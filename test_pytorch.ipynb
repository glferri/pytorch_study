{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMbElmGycKtCoR0pCi0jgsW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2YsF7gRe6eJl"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n"]},{"cell_type":"code","source":["# Download training data from open datasets.\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4A6d6z77PJ1","executionInfo":{"status":"ok","timestamp":1687065265634,"user_tz":-120,"elapsed":1559,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"8a89ddef-30be-4945-8369-b33e3e7a2839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:00<00:00, 117090912.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 6763638.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:00<00:00, 64779408.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 5659836.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]}]},{"cell_type":"code","source":["batch_size = 64\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGHNLs-v7UoL","executionInfo":{"status":"ok","timestamp":1687065286167,"user_tz":-120,"elapsed":366,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"578c02eb-22f1-405d-87a7-5898d20f1f8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S7v16PEM741G","executionInfo":{"status":"ok","timestamp":1687065433948,"user_tz":-120,"elapsed":373,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"6eae75dc-0c2b-47b9-cb6f-ae044d570147"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jun 18 05:16:56 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["print(torch.cuda.device_count())\n","print(torch.cuda.get_device_name(0))\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Gm_J5Ne8VoU","executionInfo":{"status":"ok","timestamp":1687065674166,"user_tz":-120,"elapsed":349,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"e0bfc397-283a-438e-ab44-a49ed15cee95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","Tesla T4\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YcSPKI4N8py8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3axRMIvK7dhi","executionInfo":{"status":"ok","timestamp":1687065679632,"user_tz":-120,"elapsed":595,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"663d7860-bbc8-4d10-dcf3-5a9827eb69db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"],"metadata":{"id":"VwO_P6eu9DAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"],"metadata":{"id":"F-zhwj8S9GD8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"],"metadata":{"id":"-W4UDVdi9KU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"id":"AjRxSRB69NTs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Saving Models\n","A common way to save a model is to serialize the internal state dictionary (contaning the model parameters)\n","\n"],"metadata":{"id":"dDBmRhFx_FDk"}},{"cell_type":"code","source":["torch.save(model.state_dict(), \"model.pth\")\n","print(\"Saved PyTorch Model State to model.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjYwXkFh_Wjf","executionInfo":{"status":"ok","timestamp":1687066387903,"user_tz":-120,"elapsed":325,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"80fc4c85-3889-4357-ccec-f7429ac5d548"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved PyTorch Model State to model.pth\n"]}]},{"cell_type":"markdown","source":["# Loading Models\n","The process of loading a model includes re-creating the model structure and loading the state dictionary into it\n"],"metadata":{"id":"bnTptfkO_qkk"}},{"cell_type":"code","source":["model = NeuralNetwork().to(device)\n","model.load_state_dict(torch.load(\"model.pth\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYg37wWT_3g9","executionInfo":{"status":"ok","timestamp":1687066531881,"user_tz":-120,"elapsed":7,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"b691a181-a6a1-453e-f1e0-576dbe981377"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    x = x.to(device)\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfC-ckre_EGD","executionInfo":{"status":"ok","timestamp":1687066552681,"user_tz":-120,"elapsed":594,"user":{"displayName":"Gianluca Ferri","userId":"04299550453904532187"}},"outputId":"fde674c7-2697-41fd-cadf-92836b44fa54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}]}]}